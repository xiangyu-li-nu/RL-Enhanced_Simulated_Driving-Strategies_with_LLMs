import torch
from transformers import pipeline
from prompt import *
# Loading the Llama 3.1 pre-trained model
model_id = "D:/LLM_for_AV/llama3.1-7b"
pipe = pipeline(
    "text-generation",
    model=model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
)


# Simulate historical status data of MAV and RAV
def simulate_history_state():
    # Simulation of historical state data of MAV and RAV (past positions, lanes, speeds, accelerations)
    mav_history = [
        {'x_m_t': 100, 'lane_m_t': 1, 'v_m_t': 30, 'a_m_t': 2, 'decision_m_t': 'cooperate', 'action_m_t': 'decelerate'},
        # MAV Past State 1
        {'x_m_t': 105, 'lane_m_t': 1, 'v_m_t': 32, 'a_m_t': 2.1, 'decision_m_t': 'compete', 'action_m_t': 'accelerate'},
        # MAV Past State 2
        {'x_m_t': 110, 'lane_m_t': 1, 'v_m_t': 33, 'a_m_t': 1.9, 'decision_m_t': 'cooperate',
         'action_m_t': 'Lane Change'}  # MAV past state 3
    ]

    # The historical state of the RAV, including the RAVâ€™s position, velocity, acceleration, and the decisions it made (cooperation or competition)
    rav_history = [
        {'x_r_t': 110, 'lane_r_t': 1, 'v_r_t': 28, 'a_r_t': 1.5, 'decision_r_t': 'cooperate', 'action_r_t': 'Decelerate'},
        # RAV Past Status 1
        {'x_r_t': 112, 'lane_r_t': 1, 'v_r_t': 30, 'a_r_t': 1.6, 'decision_r_t': 'compete', 'action_r_t': 'accelerate'},
        # RAV Past Status 2
        {'x_r_t': 115, 'lane_r_t': 1, 'v_r_t': 31, 'a_r_t': 1.7, 'decision_r_t': 'compete', 'action_r_t': 'Maintain Speed'}
        # RAV Past Status 3
    ]

    return mav_history, rav_history


# Simulate the current state of MAV and RAV
def simulate_current_state():
    # Current state simulation (real-time position, speed, acceleration, etc.)
    mav_state = {
        'x_m_t': 120,  # MAV Current Location
        'lane_m_t': 1,  # MAV Current Lane
        'v_m_t': 35,  # MAV current speed
        'a_m_t': 2.5,  # MAV current acceleration
        'P_cooperate_m': 0.8  # MAV predicts the probability of RAV cooperation
    }

    rav_state = {
        'x_r_t': 125,  # RAV Current location
        'lane_r_t': 1,  # RAV Current Lane
        'v_r_t': 33,  # RAV Current Speed
        'a_r_t': 1.8,  # RAV Current acceleration
        'decision_r_t': 'cooperate',  # RAV Current Decisions (Cooperation)
        'action_r_t': 'Lane Change'  # RAV Current Behavior (Merge)
    }

    return mav_state, rav_state


# Building MAV System Input Prompts

# Inference Function
def infer_mav_decision(mav_history, rav_history, mav_state, rav_state):
    # Generate MAV Input Prompt
    messages = generate_mav_prompt(mav_history, rav_history, mav_state, rav_state)

    # Call the model for inference
    outputs = pipe(messages, max_new_tokens=512)

    decision_explanation = outputs[0]["generated_text"][-1]["content"]

    decision, action = extract_wrapped_content(decision_explanation)
    # Returns the output of the model
    return {"decision_explanation":decision_explanation, "decision":decision, "action":action}

def infer_rav_decision(mav_history, rav_history, mav_state, rav_state):
    # Generate MAV Input Prompt
    messages = generate_mav_prompt(mav_history, rav_history, mav_state, rav_state)

    # Call the model for inference
    outputs = pipe(messages, max_new_tokens=512)

    decision_explanation = outputs[0]["generated_text"][-1]["content"]

    decision, action = extract_wrapped_content(decision_explanation)
    # Returns the output of the model
    return {"decision_explanation":decision_explanation, "decision":decision, "action":action}
# Main function
if __name__ == "__main__":
    # Simulate historical status data of MAV and RAV
    mav_history, rav_history = simulate_history_state()

    # Simulate the current state of MAV and RAV
    mav_state, rav_state = simulate_current_state()

    # Calling the inference function
    decision = infer_mav_decision(mav_history, rav_history, mav_state, rav_state)

    # Print the decisions and recommended actions generated by the model
    print("MAV's Decision and Suggested Action: ")
    print(decision)
